目录：

1. 简介
2. Exhaustive Grid Search
3. Randomized Parameter Optimization
4. 两种参数搜索策略区别

# 1. 简介
A parameter search consists of:
- an estimator (regressor or classifier such as `sklearn.svm.SVC()`);
- a parameter space;
- a method for searching or sampling candidates;
- a cross-validation scheme;
- a score function.

两种通用**参数搜索策略**：

- `GridSearchCV` exhaustively considers all parameter combinations, 
- while `RandomizedSearchCV` can sample a given number of candidates from a parameter space with a specified distribution. 

# 2. Exhaustive Grid Search
The grid search provided by [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) exhaustively generates candidates from a grid of parameter values specified with the `param_grid` parameter. For instance, the following `param_grid`:
```python
# 一个参数组合
param_grid1 = {
'C': [1, 10, 100, 1000], 
'kernel': ['linear']
}
# 多个参数组合
param_grid2 = [
  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},
 ]
```

# 3. Randomized Parameter Optimization
While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties.[`RandomizedSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV) implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values.

优点：

- A budget can be chosen independent of the number of parameters and possible values.
- Adding parameters that do not influence the performance does not decrease efficiency.

A computation budget, being the number of sampled candidates or sampling iterations, is specified using the `n_iter` parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified:
```python
{'C': scipy.stats.expon(scale=100),
'gamma': scipy.stats.expon(scale=.1),
'kernel': ['rbf'],
'class_weight':['balanced', None]}
```

For continuous parameters, such as `C` above, it is important to specify a continuous distribution to take full advantage of the randomization.