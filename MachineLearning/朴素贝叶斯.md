目录：

1. 基本原理
    - 相关概率知识回顾
    - 基本假设
    - 模型公式
    - 拉普拉斯修正
    - 高斯朴素贝叶斯
2. 实践

# 1. 基本原理
朴素贝叶斯是一种生成模型，它由训练数据学习联合概率分布`P(X,Y)`,然后求得后验概率分布`P(Y|X)`。
## （1）相关概率知识回顾
主要回顾两个公式：

1. 条件概率的乘法法则：

    ![条件概率乘法法则](http://i.imgur.com/lIlDyoS.png)

2. 贝叶斯公式：

    ![贝叶斯公式](http://i.imgur.com/8uu10jv.png)

这两个公式其实是一致的。
## （2）基本假设
朴素贝叶斯之所以朴素是因为它有个很简单的假设：**特征间是相互独立的**。

基于这个假设，我们有：

![Imgur](http://i.imgur.com/FqvGb2r.png)

`j`表示第j个特征；`k`表示第k个类。

## （3）模型公式
换了notation的**贝叶斯公式**：

![Imgur](http://i.imgur.com/GDvaGgR.png)

贝叶斯公式的分母是个常量，我们在计算时不予考虑。所以我们容易得到下面公式：

**模型公式**：

![Imgur](http://i.imgur.com/21mGvQF.png)

## （4）拉普拉斯修正
为了防止0概率的出现，我们需要将公式进行修正。

对**先验概率**修正：

![Imgur](http://i.imgur.com/AtK5p9e.png)

对**条件概率**修正：

![Imgur](http://i.imgur.com/rqDJZ0I.png)

当`λ=1`时，称为拉普拉斯平滑。
## （5）高斯朴素贝叶斯
高斯朴素贝叶斯解决的是如何在特征为连续值时估计条件概率分布。详细叙述见：
[高斯朴素贝叶斯——维基百科](https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8#.E9.AB.98.E6.96.AF.E6.9C.B4.E7.B4.A0.E8.B4.9D.E5.8F.B6.E6.96.AF)

# 2. 实践
使用[`GaussianNB`](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)接口

*Code Example*:
```python
>>> from sklearn import datasets
>>> iris = datasets.load_iris()
>>> from sklearn.naive_bayes import GaussianNB
>>> gnb = GaussianNB()
>>> y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)
>>> print("Number of mislabeled points out of a total %d points : %d"
...       % (iris.data.shape[0],(iris.target != y_pred).sum()))
Number of mislabeled points out of a total 150 points : 6

```

**Tips**：

1. 尽管朴素贝叶斯是个好分类器，但是它并不是一个好评估器，所以分类器的`predict_proba`函数输出不要太当回事。

<br >

**Ref**

http://scikit-learn.org/stable/modules/naive_bayes.html

[《统计学习方法》](https://github.com/wangjiang0624/Note/blob/master/MachineLearning/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF.md)